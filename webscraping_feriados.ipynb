{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01dc1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a86411",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cidades = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c826e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estados = ['sp', 'mg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8672fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    \" \": \"_\",\n",
    "    \"'\": \"\",\n",
    "    \"â\": \"a\",\n",
    "    \"ã\": \"a\",\n",
    "    \"á\": \"a\",\n",
    "    \"é\": \"e\",\n",
    "    \"ê\": \"e\",\n",
    "    \"í\": \"i\",\n",
    "    \"ó\": \"o\",\n",
    "    \"õ\": \"o\",\n",
    "    \"ô\": \"o\",\n",
    "    \"ú\": \"u\",\n",
    "    \"ç\": \"c\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab9243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5514f5b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m response  \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, headers \u001b[39m=\u001b[39m headers)\n\u001b[0;32m      5\u001b[0m response_text \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n\u001b[1;32m----> 7\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(response_text, \u001b[39m'\u001b[39;49m\u001b[39mlxml\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m cidades \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdiv_outras_cidades\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m cidades:\n",
      "File \u001b[1;32mc:\\Users\\danil\\anaconda3\\envs\\DS\\Lib\\site-packages\\bs4\\__init__.py:248\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     builder_class \u001b[39m=\u001b[39m builder_registry\u001b[39m.\u001b[39mlookup(\u001b[39m*\u001b[39mfeatures)\n\u001b[0;32m    247\u001b[0m     \u001b[39mif\u001b[39;00m builder_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m         \u001b[39mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    249\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a tree builder with the features you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequested: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Do you need to install a parser library?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m             \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(features))\n\u001b[0;32m    253\u001b[0m \u001b[39m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "for estado in estados: \n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    url = f'https://www.feriados.com.br/feriados-estado-{estado}.php?ano=2023'\n",
    "    response  = requests.get(url, headers = headers)\n",
    "    response_text = response.text\n",
    "    \n",
    "    soup = BeautifulSoup(response_text, 'lxml')\n",
    "    \n",
    "    cidades = soup.find('div', id='div_outras_cidades').find_all('a')\n",
    "    for c in cidades:\n",
    "        cidade = c.text\n",
    "        cidade_padronizado = replace_all(cidade.lower(), dic)\n",
    "        lista_cidades[f'{cidade} - {estado.upper()}'] = f'{cidade_padronizado}-{estado}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9fa9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab11d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_completa = []\n",
    "\n",
    "for nome, link in lista_cidades.items():\n",
    "    \n",
    "    lista_estado = []\n",
    "    lista_cidade = []\n",
    "    lista_datas = []\n",
    "    lista_feriados = []\n",
    "\n",
    "    \n",
    "    url = f'https://www.feriados.com.br/feriados-{link}.php?ano=2023'\n",
    "\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response_text = response.text\n",
    "\n",
    "    soup = BeautifulSoup(response_text, 'lxml')\n",
    "\n",
    "    feriads = soup.find('ul', class_='multi-column')\n",
    "    feriados = feriads.find_all('li')\n",
    "\n",
    "\n",
    "    for feriado in feriados:\n",
    "        lista_cidade.append('-'.join(nome.split('-')[:-1]).strip())\n",
    "        lista_estado.append(nome.split('-')[-1].strip())\n",
    "        \n",
    "        lista = feriado.text.split('-')\n",
    "        lista_datas.append(lista[0].strip())\n",
    "        lista_feriados.append((' '.join(lista[1:])).strip().title())\n",
    "\n",
    "    lista_completa.extend(list(zip(lista_cidade,lista_estado,lista_datas,lista_feriados)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Cidade','Estado','Data','Feriado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb62188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lista_completa, columns = columns)\n",
    "df\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Feriado.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Feriado.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index = df[df['Feriado'] == 'Finados'].index, axis = 0, inplace=True)\n",
    "df.drop(index = df[df['Feriado'] == 'Sexta Feira Da Paixão'].index, axis = 0, inplace=True)\n",
    "df.drop(index = df[df['Feriado'] == 'Terça De Carnaval'].index, axis = 0, inplace=True)\n",
    "df.replace('Dia Da Consciência Negra   Lei No. 3.249, De 18 De Novembro De 2008','Dia Da Consciência Negra', inplace=True)\n",
    "df.replace('Dia Da Consciência Negra   Lei No 1.914 De 04 De Dezembro De 2007','Dia Da Consciência Negra', inplace=True)\n",
    "df.replace('Dia Da Consciência Negra   Lei 4.731 22/12/2008.','Dia Da Consciência Negra', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f521025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a298d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Feriado'] == 'Dia Da Consciência Negra   Lei 4.731 22/12/2008.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Feriado.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30187764",
   "metadata": {},
   "outputs": [],
   "source": [
    "feriados_nacionais = ['Carnaval','Ano Novo','Nossa Senhora Aparecida','Natal','Proclamação Da República',\n",
    "                      'Dia De Finados','Dia Do Servidor Público','Dia Do Professor','Independência Do Brasil',\n",
    "                     'Corpus Christi','Dia Do Trabalho','Dia De Tiradentes','Sexta Feira Santa']\n",
    "\n",
    "conditions = [\n",
    "    (df['Feriado'].isin(feriados_nacionais)),\n",
    "    (df['Feriado'] == 'Revolução Constitucionalista')\n",
    "     ]\n",
    "\n",
    "labels = ['Feriado Nacional', 'Feriado Estadual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tipo'] = np.select(conditions, labels, default = 'Feriado Municipal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lista_feriados.csv', sep=';', encoding='UTF-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97d277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f50ff86dcc83d827658d7bf4a58af5dc80cc4a2f0dc533cdadc754e7a241a0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
